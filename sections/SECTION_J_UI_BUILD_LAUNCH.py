# ========================= SECTION J: UI BUILD & LAUNCH ========================= #
# ========================= SECTION J: UI BUILD & LAUNCH ========================= #

import gradio as gr



import gradio as gr

def _get_path(f):
    """Safe wrapper to get file path from Gradio File component"""
    if f is None: 
        return ""
    return getattr(f, "name", f)  # f.name if object, otherwise f is already path string

def validate_yolo_label(class_id: int, x_center: float, y_center: float, width: float, height: float) -> bool:
    """
    Validate YOLO label values before writing
    Returns True if valid, False if invalid
    """
    # Check class_id is in valid range [0, 1] for 2-class dataset
    if not (0 <= class_id <= 1):
        _log_warning("Label Validation", f"Invalid class_id: {class_id} (must be 0 or 1)")
        return False
    
    # Check bbox values are in [0, 1] range
    if not (0 <= x_center <= 1 and 0 <= y_center <= 1):
        _log_warning("Label Validation", f"Invalid center coordinates: ({x_center:.3f}, {y_center:.3f}) (must be in [0, 1])")
        return False
    
    # Check width and height are positive and reasonable
    if width <= 0 or height <= 0:
        _log_warning("Label Validation", f"Invalid dimensions: width={width:.3f}, height={height:.3f} (must be > 0)")
        return False
    
    # Check for tiny boxes (width/height < 0.01)
    if width < 0.01 or height < 0.01:
        _log_warning("Label Validation", f"Tiny box detected: width={width:.3f}, height={height:.3f} (min size: 0.01)")
        return False
    
    # Check bbox doesn't extend outside image bounds
    x_min = x_center - width/2
    y_min = y_center - height/2
    x_max = x_center + width/2
    y_max = y_center + height/2
    
    if x_min < 0 or y_min < 0 or x_max > 1 or y_max > 1:
        _log_warning("Label Validation", f"Bbox extends outside image: ({x_min:.3f}, {y_min:.3f}, {x_max:.3f}, {y_max:.3f})")
        return False
    
    return True

def cleanup_empty_dataset_folders(dataset_root: str):
    """
    Clean up empty dataset folders to avoid confusion
    Only keep folders that actually contain images
    """
    import glob
    import shutil
    
    _log_info("Dataset Cleanup", f"Cleaning up empty dataset folders in: {dataset_root}")
    
    # Find all versioned folders
    yolo_folders = glob.glob(os.path.join(dataset_root, "datasets", "yolo", "v*"))
    u2net_folders = glob.glob(os.path.join(dataset_root, "datasets", "u2net", "v*"))
    
    total_removed = 0
    
    # Clean YOLO folders
    for folder in yolo_folders:
        train_images = glob.glob(os.path.join(folder, "images", "train", "*.jpg"))
        if len(train_images) == 0:
            _log_info("Dataset Cleanup", f"Removing empty YOLO folder: {os.path.basename(folder)}")
            shutil.rmtree(folder, ignore_errors=True)
            total_removed += 1
    
    # Clean U¬≤-Net folders
    for folder in u2net_folders:
        train_images = glob.glob(os.path.join(folder, "images", "train", "*.jpg"))
        if len(train_images) == 0:
            _log_info("Dataset Cleanup", f"Removing empty U¬≤-Net folder: {os.path.basename(folder)}")
            shutil.rmtree(folder, ignore_errors=True)
            total_removed += 1
    
    _log_success("Dataset Cleanup", f"Removed {total_removed} empty dataset folders")
    return total_removed

def clean_dataset_class_ids(dataset_root: str, old_class_id: int = 99, new_class_id: int = 1):
    """
    Clean dataset by converting old class_id to new_class_id in all .txt files
    This fixes the issue where class_id = 99 causes Ultralytics to drop all labels
    """
    import glob
    
    _log_info("Dataset Cleaner", f"Cleaning dataset: {old_class_id} -> {new_class_id}")
    
    # Find all .txt files in labels directories - FIXED: Include all possible paths
    label_patterns = [
        # Original dataset paths
        os.path.join(dataset_root, "labels", "train", "*.txt"),
        os.path.join(dataset_root, "labels", "val", "*.txt"),
        # YOLO-specific dataset paths
        os.path.join(dataset_root, "datasets", "yolo", "*", "labels", "train", "*.txt"),
        os.path.join(dataset_root, "datasets", "yolo", "*", "labels", "val", "*.txt"),
        # Legacy paths
        os.path.join(dataset_root, "sdy_project", "labels", "train", "*.txt"),
        os.path.join(dataset_root, "sdy_project", "labels", "val", "*.txt"),
        # Any other nested paths
        os.path.join(dataset_root, "**", "labels", "train", "*.txt"),
        os.path.join(dataset_root, "**", "labels", "val", "*.txt")
    ]
    
    total_files = 0
    total_lines = 0
    converted_lines = 0
    
    for pattern in label_patterns:
        for txt_file in glob.glob(pattern):
            total_files += 1
            try:
                with open(txt_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                new_lines = []
                for line in lines:
                    total_lines += 1
                    parts = line.strip().split()
                    if parts and parts[0].isdigit():
                        class_id = int(parts[0])
                        if class_id == old_class_id:
                            # Convert old class_id to new_class_id
                            parts[0] = str(new_class_id)
                            converted_lines += 1
                            _log_info("Dataset Cleaner", f"Converted {old_class_id}->{new_class_id} in {os.path.basename(txt_file)}")
                    new_lines.append(' '.join(parts) + '\n')
                
                # Write back the cleaned file
                with open(txt_file, 'w', encoding='utf-8') as f:
                    f.writelines(new_lines)
                    
            except Exception as e:
                _log_error("Dataset Cleaner", f"Error processing {txt_file}: {e}")
    
    _log_success("Dataset Cleaner", f"Cleaned {total_files} files: {converted_lines}/{total_lines} lines converted")
    return total_files, converted_lines

def build_ui():
    with gr.Blocks(title="NCC Pipeline ‚Äî Dataset ‚Üí Train ‚Üí Warehouse Check", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # **NCC Pipeline ‚Äî Full End-to-End System**
        *Dataset Creation ‚Üí Model Training ‚Üí Warehouse Quality Check*
        
        ## üîÑ Pipeline Overview
        1. **NH√Ä CUNG C·∫§P**: Upload ·∫£nh/video ‚Üí GroundingDINO + QR + Background Removal ‚Üí Dataset (ZIP)
        2. **TRUNG GIAN**: Train YOLOv8-seg + U¬≤-Net t·ª´ dataset ‚Üí Export weights
        3. **KHO**: Load models ‚Üí QR decode + YOLO detect + U¬≤-Net segment ‚Üí Check & Export
        """)
        
        # Init section
        with gr.Row():
            init_btn = gr.Button("üöÄ Init Models", variant="primary")
            init_status = gr.Textbox(label="Status", interactive=False)
        init_btn.click(fn=init_models, outputs=init_status)
        
        # Config section
        with gr.Row():
            with gr.Column():
                # Settings Toggle
                settings_visible = gr.State(False)
                settings_toggle = gr.Button("‚öôÔ∏è Show/Hide Advanced Settings", variant="secondary")
                
                with gr.Group(visible=False) as settings_group:
                    gr.Markdown("### ‚öôÔ∏è GroundingDINO Config")
                    gdino_prompt = gr.Textbox(label="Prompt", value=CFG.gdino_prompt)
                    
                    gr.Markdown("#### üìä GroundingDINO Thresholds")
                    with gr.Row():
                        gdino_box_thr = gr.Slider(0.01, 1.0, CFG.gdino_box_thr, label="Box Threshold")
                        gdino_text_thr = gr.Slider(0.01, 1.0, CFG.gdino_text_thr, label="Text Threshold")
                        hand_detection_thr = gr.Slider(0.01, 1.0, CFG.current_hand_detection_thr, label="Hand Detection Threshold")
                    
                    gr.Markdown("### üß† DexiNed White-ring Segmentation (Main Backend)")
                    use_white_ring = gr.Checkbox(label="Use DexiNed White-ring Segmentation (Recommended)", value=CFG.use_white_ring_seg)
                    seg_mode = gr.Dropdown(["single", "components"], value=CFG.seg_mode, label="Segmentation Mode")
                    
                    # DexiNed Backend Settings
                    gr.Markdown("#### üß† DexiNed Backend")
                    with gr.Row():
                        auto_init_dexined_btn = gr.Button("üöÄ Auto-Init DexiNed", variant="primary", size="lg")
                        system_status_btn = gr.Button("üìä System Status", variant="secondary")
                    
                    with gr.Accordion("üîß Advanced DexiNed Settings", open=False):
                        dexi_onnx_path = gr.Textbox("weights/dexined.onnx", label="DexiNed ONNX path")
                        dexi_torch_path = gr.Textbox("weights/dexined.pth", label="DexiNed PyTorch path")
                        dexi_short_side = gr.Slider(512, 1280, 1024, step=32, label="DexiNed short-side resize")
                        init_dexined_btn = gr.Button("üß† Manual Init", variant="secondary")
                    
                    # Edge Detection (DexiNed + Canny fallback)
                    gr.Markdown("#### üéØ Edge Detection")
                    edge_backend = gr.Radio(["DexiNed", "Canny"], value="DexiNed", label="Edge Backend")
                    dexi_thr = gr.Slider(0.05, 0.8, CFG.video_dexi_thr, step=0.01, label="DexiNed Threshold")
                    canny_lo = gr.Slider(10, 100, CFG.canny_lo, label="Canny Low Threshold (Fallback)")
                    canny_hi = gr.Slider(50, 300, CFG.canny_hi, label="Canny High Threshold (Fallback)")
                    
                    # Morphology & Filtering
                    gr.Markdown("#### üîß Morphology & Filtering")
                    dilate_px = gr.Slider(0, 5, CFG.dilate_px, label="Dilate Iterations")
                    close_px = gr.Slider(0, 30, CFG.close_px, label="Close Kernel Size")
                    ban_border = gr.Slider(1, 50, CFG.ban_border_px, label="Ban Border Distance (px)")
                    min_area_ratio = gr.Slider(0.1, 0.8, CFG.min_area_ratio, label="Min Area Ratio")
                    rect_score_min = gr.Slider(0.3, 1.0, CFG.rect_score_min, label="Rect Score Min")
                    
                    # Shape Constraints
                    gr.Markdown("#### üìê Shape Constraints")
                    ar_min = gr.Slider(0.1, 1.0, CFG.ar_min, label="Aspect Ratio Min")
                    ar_max = gr.Slider(1.0, 3.0, CFG.ar_max, label="Aspect Ratio Max")
                    center_cov_min = gr.Slider(0.1, 1.0, CFG.center_cov_min, label="Center Coverage Min")
                    
                    # Final Processing
                    gr.Markdown("#### ‚úÇÔ∏è Final Processing")
                    erode_inner = gr.Slider(0, 10, CFG.erode_inner_px, label="Erode Inner (px)")
                    min_comp_area = gr.Slider(500, 20000, CFG.min_comp_area, label="Min Component Area")
                    
                    # Edge Smoothing
                    gr.Markdown("#### üé® Edge Smoothing")
                    smooth_mode = gr.Radio(
                        choices=["Off", "Light", "Medium", "Strong"],
                        value=CFG.smooth_mode,
                        label="Smooth Mode"
                    )
                    smooth_iterations = gr.Slider(0, 5, CFG.smooth_iterations, label="Smooth Iterations")
                    gaussian_kernel = gr.Slider(3, 15, CFG.gaussian_kernel, label="Gaussian Kernel")
                    
                    # Post-processing
                    gr.Markdown("#### üîß Post-processing")
                    use_shadow_robust_edges = gr.Checkbox(label="Shadow Robust Edges", value=CFG.use_shadow_robust_edges)
                    force_rectify = gr.Radio(
                        choices=["Off", "Square", "Rectangle", "Robust (erode-fit-pad)"],
                        value=CFG.force_rectify,
                        label="Force Rectify"
                    )
                    rect_pad = gr.Slider(0, 20, CFG.rect_pad, label="Rectify Padding (px)")
                    use_convex_hull = gr.Checkbox(label="Use Convex Hull", value=CFG.use_convex_hull)
                    
                    # GPU Settings
                    gr.Markdown("#### üöÄ GPU Settings")
                    use_gpu = gr.Checkbox(CFG.video_use_gpu, label="GPU Acceleration")
                    
                    gr.Markdown("### üé® Legacy Background Removal Config (Disabled when White-ring is ON)")
                    bg_model = gr.Dropdown(
                         ["u2netp", "u2net", "u2net_human_seg"], 
                         value=CFG.bg_removal_model, 
                         label="Model",
                         info="u2net: U¬≤-Net full | u2netp: U¬≤-Net lite | u2net_human_seg: Human segmentation",
                         interactive=False
                     )
                    feather = gr.Slider(0, 20, CFG.feather_px, label="Feather (px)", interactive=False)
                    
                    update_btn = gr.Button("üîÑ Update Config", variant="secondary")
                    config_status = gr.Textbox(label="Config Status", interactive=False)
                
                # Toggle settings visibility
                def toggle_settings(visible):
                    return gr.update(visible=not visible), not visible
                
                settings_toggle.click(
                    fn=toggle_settings,
                    inputs=[settings_visible],
                    outputs=[settings_group, settings_visible]
                )
                
                # Enable/disable legacy config based on white-ring checkbox
                def toggle_legacy_config(use_white_ring):
                    return gr.update(interactive=not use_white_ring)
                
                use_white_ring.change(
                    fn=toggle_legacy_config,
                    inputs=[use_white_ring],
                    outputs=[bg_model, feather]
                )
                
                # DexiNed Event Handlers
                auto_init_dexined_btn.click(
                    fn=auto_init_dexined,
                    inputs=[],
                    outputs=[config_status]
                )
                
                init_dexined_btn.click(
                    fn=init_dexined_backend,
                    inputs=[dexi_onnx_path, dexi_torch_path, dexi_short_side],
                    outputs=[config_status]
                )
                
                system_status_btn.click(
                    fn=get_system_status,
                    inputs=[],
                    outputs=[config_status]
                )
                
                update_btn.click(
                    fn=update_gdino_params,
                    inputs=[gdino_prompt, gdino_box_thr, gdino_text_thr, hand_detection_thr, bg_model, feather, use_white_ring, seg_mode, 
                           edge_backend, dexi_thr, canny_lo, canny_hi, dilate_px, close_px, ban_border, min_area_ratio, rect_score_min,
                           ar_min, ar_max, center_cov_min, erode_inner, min_comp_area, smooth_mode, 
                           smooth_iterations, gaussian_kernel, use_shadow_robust_edges, force_rectify, 
                           rect_pad, use_convex_hull, use_gpu],
                    outputs=[config_status]
                )
        
        # Tab 1: Dataset Creation
        with gr.Tab("üì¶ Create Dataset"):
            gr.Markdown("### Upload ·∫£nh/video ƒë·ªÉ t·∫°o dataset")
            
            # Unified Upload Section
            with gr.Group():
                gr.Markdown(f"""
                #### üìÅ Upload Media Files
                **üöÄ System Status**: {'GPU Available' if CUDA_AVAILABLE else 'CPU Only'} | **üß† DexiNed**: {'Ready' if EDGE.dexi and EDGE.dexi.available() else 'Not Initialized'}
                """)
                
                with gr.Row():
                    # Single Upload
                    with gr.Column():
                        gr.Markdown("### üì∏ Single Upload")
                        supplier_input = gr.Textbox(label="Supplier/Batch ID", placeholder="e.g., supplier_A, batch_001", info="Optional: for dataset versioning")
                        cam = gr.Image(label="Webcam", sources=["webcam"])
                        img_upload = gr.Image(label="Upload Image", sources=["upload"], type="numpy")
                        vid_upload = gr.File(label="Upload Video", file_types=["video"])
                        run_btn = gr.Button("üß∞ Process Single", variant="primary")
                    
                    # Multiple Upload
                    with gr.Column():
                        gr.Markdown("### üìÅ Multiple Upload (Batch)")
                        multi_supplier_input = gr.Textbox(label="Supplier/Batch ID", placeholder="e.g., supplier_A, batch_001", info="Optional: for dataset versioning")
                        multi_img_upload = gr.File(
                            label="Upload Multiple Images", 
                            file_types=["image"], 
                            file_count="multiple"
                        )
                        multi_vid_upload = gr.File(
                            label="Upload Multiple Videos", 
                            file_types=["video"], 
                            file_count="multiple"
                        )
                        run_multi_btn = gr.Button("üöÄ Process Multiple", variant="primary", size="lg")
            
            
            gr.Markdown("""
            ### üì∏ Preview Full Pipeline
            **2 ·∫£nh preview s·∫Ω hi·ªÉn th·ªã (ch·ªâ khi QR decode th√†nh c√¥ng):**
            1. **GroundingDINO Detection**: Bbox detection c·ªßa h·ªôp v√† tr√°i c√¢y
            2. **White-ring Segmentation**: 
               - **üî≤ Enhanced White-ring**: Vi·ªÅn tr·∫Øng + mask container v·ªõi contour filtering, edge smoothing, force rectify
               - **‚ùå QR Failed**: ·∫¢nh s·∫Ω b·ªã lo·∫°i b·ªè n·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c QR code
            
            ### üìÅ Multiple Upload Features
            - **Batch Processing**: Upload nhi·ªÅu ·∫£nh/video c√πng l√∫c
            - **Progress Tracking**: Hi·ªÉn th·ªã ti·∫øn ƒë·ªô x·ª≠ l√Ω t·ª´ng file
            - **Error Handling**: B√°o l·ªói chi ti·∫øt cho t·ª´ng file th·∫•t b·∫°i
            - **Summary Report**: T·ªïng k·∫øt s·ªë l∆∞·ª£ng th√†nh c√¥ng/th·∫•t b·∫°i
            - **Individual Previews**: Preview ri√™ng cho t·ª´ng file ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng
            
            ### üìä Dataset Configuration
            - **Train/Val Split**: 70%/30% (tƒÉng validation data)
            - **Frames per Video**: 390 frames (tƒÉng 30% t·ª´ 300)
            - **Step Size**: 2 (l·∫•y m·ªói 2 frame)
            - **Enhanced White-ring Features**:
              - **Contour Area Filtering**: Ch·ªâ gi·ªØ contour l·ªõn nh·∫•t (lo·∫°i b·ªè fragments)
              - **Edge Smoothing**: Medium mode v·ªõi 2 iterations, kernel 7
              - **Force Rectify**: Rectangle mode v·ªõi anti-aliasing
              - **Shadow Robust Edges**: Kh√°ng b√≥ng ƒë·ªï
              - **Single/Components**: 1 mask to√†n b·ªô ho·∫∑c t√°ch components
            - **Legacy U¬≤-Net**: Ch·ªâ active khi White-ring t·∫Øt
            """)
            
            # Output Components
            gallery = gr.Gallery(label="Preview Full Pipeline", columns=2, height=400, show_label=True)
            meta_box = gr.Textbox(label="Metadata", lines=8)
            ds_zip = gr.File(label="Download Dataset (ZIP)")
            
            # Multiple Upload Output Components
            multi_gallery = gr.Gallery(label="Multiple Upload Preview", columns=2, height=400, show_label=True)
            multi_meta_box = gr.Textbox(label="Multiple Upload Metadata", lines=8)
            multi_ds_zip = gr.File(label="Download Multiple Dataset (ZIP)")
            
            # Event Handlers
            run_btn.click(fn=handle_capture, inputs=[cam, img_upload, vid_upload, supplier_input], outputs=[gallery, meta_box, ds_zip])
            
            # Multiple Upload Handler
            def process_multiple_files(multi_images, multi_videos, supplier_id):
                """Process multiple uploaded files"""
                if not multi_images and not multi_videos:
                    return None, "No files uploaded", None
                
                # Convert file paths to images for processing
                images = []
                videos = []
                
                # Process multiple images
                if multi_images:
                    for img_file in multi_images:
                        try:
                            img_path = _get_path(img_file)
                            img = cv2.imread(img_path)
                            if img is not None:
                                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                                images.append(img_rgb)
                        except Exception as e:
                            _log_error("Multi Upload", e, f"Failed to load image: {img_path}")
                
                # Process multiple videos (just store paths)
                if multi_videos:
                    videos = [_get_path(vid_file) for vid_file in multi_videos]
                
                return handle_multiple_uploads(images, videos, supplier_id)
            
            run_multi_btn.click(
                fn=process_multiple_files,
                inputs=[multi_img_upload, multi_vid_upload, multi_supplier_input],
                outputs=[multi_gallery, multi_meta_box, multi_ds_zip]
            )
            
            
            
        
        # (Removed advanced QR Generator tab; keeping only Simple)
        
        # Tab 3: Real-time Camera Processing
        with gr.Tab("üìπ Real-time Camera"):
            gr.Markdown(f"""
            ### üìπ Real-time Camera Processing
            **T√≠nh nƒÉng:**
            - **Real-time processing** v·ªõi camera
            - **DexiNed/Canny edge detection** v·ªõi auto-download
            - **GPU acceleration** n·∫øu c√≥
            - **Live parameter adjustment**
            - **4 Rectify Modes**: Off, Rectangle, Robust (erode-fit-pad), Square
            - **Pair-edge Filter**: Advanced edge filtering
            
            **üöÄ System Status**: {'GPU Available' if CUDA_AVAILABLE else 'CPU Only'} | **üß† DexiNed**: {'Ready' if EDGE.dexi and EDGE.dexi.available() else 'Not Initialized'}
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    # Camera Controls
                    gr.Markdown("### üìπ Camera Controls")
                    camera_input = gr.Image(label="Camera Input", streaming=True)
                    
                    # Processing Parameters
                    gr.Markdown("### ‚öôÔ∏è Processing Parameters")
                    cam_backend = gr.Radio(["DexiNed", "Canny"], value=CFG.video_backend, label="Edge Backend")
                    cam_dexi_thr = gr.Slider(0.05, 0.8, CFG.video_dexi_thr, step=0.01, label="DexiNed Threshold")
                    cam_canny_lo = gr.Slider(0, 255, CFG.video_canny_lo, step=1, label="Canny Low")
                    cam_canny_hi = gr.Slider(0, 255, CFG.video_canny_hi, step=1, label="Canny High")
                    
                    # Morphology
                    cam_dilate_iters = gr.Slider(0, 5, CFG.video_dilate_iters, step=1, label="Dilate Iterations")
                    cam_close_kernel = gr.Slider(3, 31, CFG.video_close_kernel, step=2, label="Close Kernel")
                    cam_min_area_ratio = gr.Slider(5, 80, CFG.video_min_area_ratio, step=5, label="Min Area Ratio (%)")
                    cam_rect_score_min = gr.Slider(0.3, 0.95, CFG.video_rect_score_min, step=0.05, label="Rect Score Min")
                    
                    # Shape Filtering
                    cam_ar_min = gr.Slider(0.4, 1.0, CFG.video_ar_min, step=0.1, label="AR Min")
                    cam_ar_max = gr.Slider(1.0, 3.0, CFG.video_ar_max, step=0.1, label="AR Max")
                    cam_erode_inner = gr.Slider(0, 10, CFG.video_erode_inner, step=1, label="Erode Inner (px)")
                    
                    # Smoothing
                    cam_smooth_close = gr.Slider(0, 31, CFG.video_smooth_close, step=1, label="Smooth Close")
                    cam_smooth_open = gr.Slider(0, 15, CFG.video_smooth_open, step=1, label="Smooth Open")
                    cam_use_hull = gr.Checkbox(CFG.video_use_hull, label="Use Convex Hull")
                    
                    # Rectification
                    cam_rectify_mode = gr.Radio(["Off", "Rectangle", "Robust (erode-fit-pad)", "Square"], 
                                               value=CFG.video_rectify_mode, label="Rectify Mode")
                    cam_rect_pad = gr.Slider(0, 20, CFG.video_rect_pad, step=1, label="Rectify Padding (px)")
                    cam_expand_factor = gr.Slider(0.5, 2.0, CFG.video_expand_factor, step=0.1, label="Expand Factor")
                    
                    # Display
                    cam_mode = gr.Radio(["Mask Only", "Components Inside"], value=CFG.video_mode, label="Display Mode")
                    cam_min_comp_area = gr.Slider(0, 10000, CFG.video_min_comp_area, step=500, label="Min Component Area")
                    cam_show_green_frame = gr.Checkbox(CFG.video_show_green_frame, label="Show Green Frame")
                    
                    # Pair-edge Filter
                    cam_use_pair_filter = gr.Checkbox(CFG.video_use_pair_filter, label="Use Pair-edge Filter")
                    cam_pair_min_gap = gr.Slider(2, 20, CFG.video_pair_min_gap, step=1, label="Pair Min Gap (px)")
                    cam_pair_max_gap = gr.Slider(8, 40, CFG.video_pair_max_gap, step=1, label="Pair Max Gap (px)")
                    
                    # GPU
                    cam_use_gpu = gr.Checkbox(CFG.video_use_gpu, label="GPU Acceleration")
                    
                    # DexiNed Auto-Init for Camera
                    gr.Markdown("### üß† DexiNed Setup")
                    cam_auto_init_btn = gr.Button("üöÄ Auto-Init DexiNed", variant="primary")
                    
                    # Control Buttons
                    start_camera_btn = gr.Button("üìπ Start Camera Processing", variant="primary", size="lg")
                    stop_camera_btn = gr.Button("‚èπÔ∏è Stop Camera", variant="stop")
                    
                    # Status
                    camera_status = gr.Textbox(label="Camera Status", lines=2, interactive=False)
                
                with gr.Column(scale=2):
                    # Camera Output
                    gr.Markdown("### üìä Camera Output")
                    camera_output = gr.Image(label="Processed Camera Feed", height=600)
                    camera_info = gr.Textbox(label="Processing Info", lines=3, interactive=False)
            
            # Camera processing function
            def process_camera_live(frame, backend, dexi_thr, canny_lo, canny_hi,
                                  dilate_iters, close_kernel, min_area_ratio, rect_score_min,
                                  ar_min, ar_max, erode_inner, smooth_close, smooth_open, use_hull,
                                  rectify_mode, rect_pad, expand_factor, mode, min_comp_area,
                                  show_green_frame, use_pair_filter, pair_min_gap, pair_max_gap, use_gpu):
                """Process camera frame in real-time"""
                if frame is None:
                    return None, "No camera input"
                
                try:
                    # Set GPU mode
                    EDGE.set_gpu_mode(use_gpu)
                    
                    # Process frame
                    processed_frame = process_camera_frame(
                        frame, backend, canny_lo, canny_hi, dexi_thr,
                        dilate_iters, close_kernel, min_area_ratio, rect_score_min,
                        ar_min, ar_max, erode_inner, smooth_close, smooth_open, use_hull,
                        rectify_mode, rect_pad, min_comp_area, mode, show_green_frame, expand_factor,
                        use_pair_filter, pair_min_gap, pair_max_gap, None
                    )
                    
                    if processed_frame is not None:
                        gpu_info = "[GPU]" if EDGE.use_gpu else "[CPU]"
                        info = f"Backend: {backend} | GPU: {gpu_info} | Real-time processing active"
                        return processed_frame, info
                    else:
                        return None, "Processing failed"
                        
                except Exception as e:
                    return None, f"Error: {str(e)}"
            
            # Event handlers
            cam_auto_init_btn.click(
                fn=auto_init_dexined,
                inputs=[],
                outputs=[camera_status]
            )
            
            # Event handlers for real-time processing
            camera_input.change(
                fn=process_camera_live,
                inputs=[
                    camera_input, cam_backend, cam_dexi_thr, cam_canny_lo, cam_canny_hi,
                    cam_dilate_iters, cam_close_kernel, cam_min_area_ratio, cam_rect_score_min,
                    cam_ar_min, cam_ar_max, cam_erode_inner, cam_smooth_close, cam_smooth_open,
                    cam_use_hull, cam_rectify_mode, cam_rect_pad, cam_expand_factor, cam_mode,
                    cam_min_comp_area, cam_show_green_frame, cam_use_pair_filter, cam_pair_min_gap,
                    cam_pair_max_gap, cam_use_gpu
                ],
                outputs=[camera_output, camera_info]
            )
        
        # Tab 4: QR Generator (Simple)
        with gr.Tab("üéØ QR Generator (Simple)"):
            gr.Markdown("### ƒê∆°n gi·∫£n: Box ID (t√πy ch·ªçn), T√™n tr√°i c√¢y, S·ªë l∆∞·ª£ng ‚Üí QR id-only")
            
            with gr.Row():
                with gr.Column():
                    box_id_input_s = gr.Textbox(label="Box ID", placeholder="Auto-generate if empty")
                    fruit_name_s = gr.Textbox(label="Fruit Name", value="Orange")
                    quantity_s = gr.Number(label="Quantity", value=1)
                    
                    generate_qr_btn_s = gr.Button("üéØ Generate QR + Save Metadata", variant="primary")
                
                with gr.Column():
                    qr_image = gr.Image(label="QR Code", type="numpy")
                    qr_content = gr.Textbox(label="QR ID (payload)", lines=2)
                    json_path_simple = gr.Textbox(label="JSON Path (edit this file)", lines=2)
                    download_qr = gr.File(label="Download QR")
            
            with gr.Row():
                gr.Markdown("### üîé Decode QR (Upload ·∫£nh QR ƒë·ªÉ xem log)")
                qr_upload = gr.File(label="Upload QR Image", file_types=["image"])
                qr_decode_log = gr.Textbox(label="QR Decode Log", lines=12, interactive=False)
            
            def _wrap_handle_qr_generation(box_id, fruit_name_in, qty, dummy2=None, dummy3=None, dummy4=None, dummy5=None, dummy6=None):
                # Keep signature flexible; map simple inputs to original handler
                return handle_qr_generation(box_id, fruit_name_in, int(qty or 0), "", 0, "", int(qty or 0), "")

            # Main tab button wiring removed (only Simple tab retained)

            # Simple tab button wiring
            generate_qr_btn_s.click(
                fn=lambda b, f, q: _wrap_handle_qr_generation(b, f, q),
                inputs=[box_id_input_s, fruit_name_s, quantity_s],
                outputs=[qr_image, qr_content, json_path_simple, download_qr]
            )

            # Decode uploaded QR and show GDINO-related info
            qr_upload.change(
                fn=decode_qr_info,
                inputs=[qr_upload],
                outputs=[qr_decode_log]
            )
        
        # Tab 3: Train SDY (YOLOv8)
        with gr.Tab("üèãÔ∏è Train YOLOv8"):
            gr.Markdown("### Train YOLOv8 model (SDY) v·ªõi Hyperparameters")
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("#### ‚öôÔ∏è Training Parameters")
                    yolo_epochs = gr.Slider(10, 200, CFG.yolo_epochs, step=10, label="Epochs", info="S·ªë v√≤ng l·∫∑p ƒë√†o t·∫°o")
                    yolo_batch = gr.Slider(1, 32, CFG.yolo_batch, step=1, label="Batch Size", info="S·ªë ·∫£nh m·ªói b∆∞·ªõc")
                    yolo_imgsz = gr.Slider(320, 1280, CFG.yolo_imgsz, step=32, label="Image Size", info="K√≠ch th∆∞·ªõc ·∫£nh hu·∫•n luy·ªán")
                    
                    gr.Markdown("#### üìà Learning Rate")
                    yolo_lr0 = gr.Slider(0.001, 0.1, CFG.yolo_lr0, step=0.001, label="Initial LR", info="T·ªëc ƒë·ªô h·ªçc ban ƒë·∫ßu")
                    yolo_lrf = gr.Slider(0.001, 0.1, CFG.yolo_lrf, step=0.001, label="Final LR", info="T·ªëc ƒë·ªô h·ªçc cu·ªëi")
                    yolo_weight_decay = gr.Slider(0.0001, 0.01, CFG.yolo_weight_decay, step=0.0001, label="Weight Decay", info="H·ªá s·ªë suy gi·∫£m tr·ªçng s·ªë")
                    
                    gr.Markdown("#### üîÑ Augmentation")
                    yolo_mosaic = gr.Checkbox(CFG.yolo_mosaic, label="Mosaic", info="Gh√©p 4 ·∫£nh th√†nh 1")
                    yolo_flip = gr.Checkbox(CFG.yolo_flip, label="Horizontal Flip", info="L·∫≠t ngang ·∫£nh")
                    yolo_hsv = gr.Checkbox(CFG.yolo_hsv, label="HSV Augmentation", info="Thay ƒë·ªïi m√†u s·∫Øc")
                    
                    gr.Markdown("#### ‚ö° Performance")
                    yolo_workers = gr.Slider(1, 16, CFG.yolo_workers, step=1, label="Workers", info="S·ªë lu·ªìng x·ª≠ l√Ω d·ªØ li·ªáu")
                
                with gr.Column():
                    train_sdy = gr.Button("üèãÔ∏è Train YOLOv8", variant="primary", size="lg")
                    sdy_log = gr.Textbox(label="Training Log", lines=8)
                    sdy_zip = gr.File(label="Download Weights (ZIP)")
            
            # Update config button for YOLO
            update_yolo_btn = gr.Button("üîÑ Update YOLO Config", variant="secondary")
            yolo_config_status = gr.Textbox(label="Config Status", interactive=False)
            
            train_sdy.click(fn=train_sdy_btn, outputs=[sdy_log, sdy_zip])
            
            # Update YOLO config function
            def update_yolo_config(epochs, batch, imgsz, lr0, lrf, weight_decay, mosaic, flip, hsv, workers):
                try:
                    CFG.yolo_epochs = int(epochs)
                    CFG.yolo_batch = int(batch)
                    CFG.yolo_imgsz = int(imgsz)
                    CFG.yolo_lr0 = float(lr0)
                    CFG.yolo_lrf = float(lrf)
                    CFG.yolo_weight_decay = float(weight_decay)
                    CFG.yolo_mosaic = bool(mosaic)
                    CFG.yolo_flip = bool(flip)
                    CFG.yolo_hsv = bool(hsv)
                    CFG.yolo_workers = int(workers)
                    
                    return f"‚úÖ YOLO Config Updated:\nEpochs: {epochs}, Batch: {batch}, ImgSize: {imgsz}\nLR0: {lr0}, LRF: {lrf}, WeightDecay: {weight_decay}\nMosaic: {mosaic}, Flip: {flip}, HSV: {hsv}\nWorkers: {workers}"
                except Exception as e:
                    return f"‚ùå Error updating YOLO config: {str(e)}"
            
            update_yolo_btn.click(
                fn=update_yolo_config,
                inputs=[yolo_epochs, yolo_batch, yolo_imgsz, yolo_lr0, yolo_lrf, yolo_weight_decay, 
                       yolo_mosaic, yolo_flip, yolo_hsv, yolo_workers],
                outputs=[yolo_config_status]
            )
        
        # Tab 5: Train U¬≤-Net
        with gr.Tab("üéì Train U¬≤-Net"):
            gr.Markdown("### Train U¬≤-Net for Background Removal (from scratch) v·ªõi Hyperparameters")
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("#### ‚öôÔ∏è Training Parameters")
                    u2_epochs = gr.Slider(10, 200, CFG.u2_epochs, step=10, label="Epochs", info="S·ªë v√≤ng l·∫∑p ƒë√†o t·∫°o")
                    u2_batch = gr.Slider(1, 32, CFG.u2_batch, step=1, label="Batch Size", info="S·ªë ·∫£nh m·ªói b∆∞·ªõc")
                    u2_imgsz = gr.Slider(256, 512, CFG.u2_imgsz, step=32, label="Image Size", info="K√≠ch th∆∞·ªõc ·∫£nh hu·∫•n luy·ªán")
                    
                    gr.Markdown("#### üìà Learning & Optimization")
                    u2_lr = gr.Slider(0.0001, 0.01, CFG.u2_lr, step=0.0001, label="Learning Rate", info="T·ªëc ƒë·ªô h·ªçc")
                    u2_optimizer = gr.Dropdown(["AdamW", "SGD"], value=CFG.u2_optimizer, label="Optimizer", info="Thu·∫≠t to√°n t·ªëi ∆∞u")
                    u2_loss = gr.Dropdown(["BCEDice", "BCE", "Dice"], value=CFG.u2_loss, label="Loss Function", info="H√†m m·∫•t m√°t")
                    
                    gr.Markdown("#### ‚ö° Performance")
                    u2_workers = gr.Slider(1, 8, CFG.u2_workers, step=1, label="Workers", info="S·ªë lu·ªìng x·ª≠ l√Ω d·ªØ li·ªáu")
                    u2_amp = gr.Checkbox(CFG.u2_amp, label="Mixed Precision", info="S·ª≠ d·ª•ng AMP ƒë·ªÉ tƒÉng t·ªëc")
                    
                    gr.Markdown("#### üéØ Advanced Settings")
                    u2_weight_decay = gr.Slider(0.0001, 0.01, CFG.u2_weight_decay, step=0.0001, label="Weight Decay", info="H·ªá s·ªë suy gi·∫£m tr·ªçng s·ªë")
                    u2_use_edge_loss = gr.Checkbox(CFG.u2_use_edge_loss, label="Edge Loss", info="S·ª≠ d·ª•ng edge loss ƒë·ªÉ c·∫£i thi·ªán boundary")
                    u2_edge_loss_weight = gr.Slider(0.01, 0.5, CFG.u2_edge_loss_weight, step=0.01, label="Edge Loss Weight", info="Tr·ªçng s·ªë cho edge loss")
                
                with gr.Column():
                    train_u2 = gr.Button("üèãÔ∏è Train U¬≤-Net", variant="primary", size="lg")
                    u2_log = gr.Textbox(label="Training Log", lines=8)
                    
                    with gr.Row():
                        u2_zip = gr.File(label="Download Weights (ZIP)")
                        u2_onnx = gr.File(label="Download ONNX")
            
            # Update config button for U¬≤-Net
            update_u2_btn = gr.Button("üîÑ Update U¬≤-Net Config", variant="secondary")
            u2_config_status = gr.Textbox(label="Config Status", interactive=False)
            
            train_u2.click(fn=train_u2net_btn, outputs=[u2_log, u2_zip, u2_onnx])
            
            # Update U¬≤-Net config function
            def update_u2net_config(epochs, batch, imgsz, lr, optimizer, loss, workers, amp, weight_decay, use_edge_loss, edge_loss_weight):
                try:
                    CFG.u2_epochs = int(epochs)
                    CFG.u2_batch = int(batch)
                    CFG.u2_imgsz = int(imgsz)
                    CFG.u2_lr = float(lr)
                    CFG.u2_optimizer = str(optimizer)
                    CFG.u2_loss = str(loss)
                    CFG.u2_workers = int(workers)
                    CFG.u2_amp = bool(amp)
                    CFG.u2_weight_decay = float(weight_decay)
                    CFG.u2_use_edge_loss = bool(use_edge_loss)
                    CFG.u2_edge_loss_weight = float(edge_loss_weight)
                    
                    return f"‚úÖ U¬≤-Net Config Updated:\nEpochs: {epochs}, Batch: {batch}, ImgSize: {imgsz}\nLR: {lr}, Optimizer: {optimizer}, Loss: {loss}\nWorkers: {workers}, AMP: {amp}\nWeightDecay: {weight_decay}, EdgeLoss: {use_edge_loss}, EdgeWeight: {edge_loss_weight}"
                except Exception as e:
                    return f"‚ùå Error updating U¬≤-Net config: {str(e)}"
            
            update_u2_btn.click(
                fn=update_u2net_config,
                inputs=[u2_epochs, u2_batch, u2_imgsz, u2_lr, u2_optimizer, u2_loss, u2_workers, u2_amp, 
                       u2_weight_decay, u2_use_edge_loss, u2_edge_loss_weight],
                outputs=[u2_config_status]
            )
        
        # Tab 6: WAREHOUSE CHECK (M·ªöI)
        with gr.Tab("üè≠ Kho ‚Äì Ki·ªÉm tra & L·ªçc"):
            gr.Markdown("""
            ### üè≠ Ki·ªÉm tra H√†ng T·∫°i Kho
            **Pipeline**: QR decode ‚Üí YOLO detect (box + fruits) ‚Üí **QR-YOLO Validation** ‚Üí U¬≤-Net segment ‚Üí Check & Export
            
            **Quy tr√¨nh chi ti·∫øt**:
            1. **QR Decode**: ƒê·ªçc th√¥ng tin box v√† danh s√°ch tr√°i c√¢y t·ª´ QR code
            2. **YOLO Detection**: Ph√°t hi·ªán box v√† c√°c tr√°i c√¢y trong ·∫£nh
            3. **üÜï QR-YOLO Validation**: So s√°nh s·ªë l∆∞·ª£ng tr√°i c√¢y t·ª´ QR v·ªõi YOLO detection
               - ‚úÖ **Pass**: S·ªë l∆∞·ª£ng kh·ªõp (cho ph√©p sai l·ªách ¬±20%) ‚Üí Ti·∫øp t·ª•c U¬≤-Net
               - ‚ùå **Fail**: S·ªë l∆∞·ª£ng kh√¥ng kh·ªõp ‚Üí B·ªè qua U¬≤-Net, hi·ªÉn th·ªã l·ªói
            4. **U¬≤-Net Segmentation**: Ch·ªâ ch·∫°y khi validation passed, segment box region
            5. **Deskew** (t√πy ch·ªçn): Xoay th·∫≥ng h·ªôp nghi√™ng
            6. **Export**: Xu·∫•t k·∫øt qu·∫£ detection + segmentation
            
            **H∆∞·ªõng d·∫´n**:
            1. Load YOLO model (best.pt t·ª´ tab Train YOLOv8)
            2. Load U¬≤-Net model (best.pth t·ª´ tab Train U¬≤-Net)
            3. Upload ·∫£nh ho·∫∑c ch·ª•p t·ª´ webcam
            4. Xem k·∫øt qu·∫£ validation + detection + segmentation
            5. Export k·∫øt qu·∫£ n·∫øu c·∫ßn
            """)
            
            # Model loading section
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### üì¶ Load YOLO Model")
                    yolo_upload = gr.File(label="Upload YOLO weights (.pt)", file_types=[".pt"])
                    load_yolo_btn = gr.Button("üîÑ Load YOLO", variant="secondary")
                    yolo_status = gr.Textbox(label="YOLO Status", lines=2, interactive=False)
                
                with gr.Column():
                    gr.Markdown("### üé® Load U¬≤-Net Model")
                    u2net_upload = gr.File(label="Upload U¬≤-Net weights (.pth)", file_types=[".pth"])
                    load_u2net_btn = gr.Button("üîÑ Load U¬≤-Net", variant="secondary")
                    u2net_status = gr.Textbox(label="U¬≤-Net Status", lines=2, interactive=False)
            
            # Input section
            gr.Markdown("### üì∑ Input")
            with gr.Row():
                warehouse_cam = gr.Image(label="Webcam", type="numpy")
                warehouse_upload = gr.Image(label="Upload Image", type="numpy")
            
            # Deskew options
            gr.Markdown("### üîÑ Processing Options")
            with gr.Row():
                enable_deskew = gr.Checkbox(CFG.enable_deskew, label="Deskew Box (remove BG + rotate 90¬∞ align)", 
                                          info="T·ª± ƒë·ªông xoay th·∫≥ng h·ªôp nghi√™ng")
                deskew_method = gr.Dropdown(["minAreaRect", "PCA", "heuristic"], value=CFG.deskew_method, 
                                          label="Deskew Method", info="Ph∆∞∆°ng ph√°p t√≠nh g√≥c xoay")
            
            check_btn = gr.Button("üîç Run Warehouse Check", variant="primary", size="lg")
            
            # Output section
            warehouse_gallery = gr.Gallery(label="Results", columns=2, height=400)
            warehouse_log = gr.Textbox(label="Check Log", lines=10, interactive=False)
            
            # Event handlers
            load_yolo_btn.click(
                fn=lambda f: load_warehouse_yolo(_get_path(f))[1],
                inputs=[yolo_upload],
                outputs=[yolo_status]
            )
            
            load_u2net_btn.click(
                fn=lambda f: load_warehouse_u2net(_get_path(f))[1],
                inputs=[u2net_upload],
                outputs=[u2net_status]
            )
            
            def handle_warehouse_check(cam_img, upload_img, deskew_enabled, deskew_meth):
                # Update global config
                CFG.enable_deskew = deskew_enabled
                CFG.deskew_method = deskew_meth
                
                # Prioritize upload over cam
                input_img = upload_img if upload_img is not None else cam_img
                if input_img is None:
                    return None, "[ERROR] No image provided"
                
                # FIXED: Only return first 2 values, ignore results
                vis_images, log_msg, _ = handle_warehouse_upload(input_img, deskew_enabled)
                return vis_images, log_msg
            
            check_btn.click(
                fn=handle_warehouse_check,
                inputs=[warehouse_cam, warehouse_upload, enable_deskew, deskew_method],
                outputs=[warehouse_gallery, warehouse_log]
            )
        
        gr.Markdown("""
        ---
        **Pipeline Summary**:
        - **Dataset**: GroundingDINO + QR validation + Background Removal ‚Üí Clean dataset (images + masks)
        - **Training**: YOLOv8 (box detection) + U¬≤-Net (segmentation from scratch)
        - **Warehouse**: QR decode + YOLO detect + U¬≤-Net segment ‚Üí Quality check
        
        **Key Features**:
        - ‚úÖ Full end-to-end pipeline
        - ‚úÖ Train from scratch (no pretrained weights for U¬≤-Net)
        - ‚úÖ Warehouse quality control with dual models
        - ‚úÖ Export all results (dataset ZIP, weights ZIP, check results)
        """)
    
    return demo

if __name__ == "__main__":
    ui = build_ui()
    ui.queue().launch(server_name="127.0.0.1", server_port=7860)

