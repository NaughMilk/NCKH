#!/usr/bin/env python3
"""
White Ring Segmentation - Gradio Demo
=====================================
Demo ·ª©ng d·ª•ng White Ring Segmentation v·ªõi logging chi ti·∫øt cho b√°o c√°o.

M·ª•c ti√™u: T√°ch ch√≠nh x√°c v√πng "h·ªôp ch·ª©a" b·∫±ng pipeline d·ª±a v√†o bi√™n tr·∫Øng quanh th√†nh h·ªôp.
"""

import gradio as gr
import cv2
import numpy as np
import time
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class WhiteRingSegmenter:
    """White Ring Segmentation v·ªõi logging chi ti·∫øt"""
    
    def __init__(self):
        self.edge_backend = "canny"  # canny, dexined
        self.canny_low = 50
        self.canny_high = 150
        self.dexined_threshold = 0.1
        self.min_gap = 4
        self.max_gap = 18
        self.min_area_ratio = 0.1
        self.rect_score_min = 0.7
        self.aspect_ratio_min = 0.3
        self.aspect_ratio_max = 3.0
        self.erode_inner = 3
        self.convex_hull = False
        self.rectify_mode = "robust"  # square, rectangle, robust
        self.rect_pad = 8
        
    def preprocess_image(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """Ti·ªÅn x·ª≠ l√Ω ·∫£nh BGR v·ªõi chu·∫©n ho√° ƒë·ªô t∆∞∆°ng ph·∫£n-chi ti·∫øt"""
        start_time = time.time()
        
        # Chu·∫©n ho√° ƒë·ªô t∆∞∆°ng ph·∫£n
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        
        # Merge l·∫°i
        enhanced = cv2.merge([l, a, b])
        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        
        # Convert to grayscale
        gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
        
        processing_time = time.time() - start_time
        
        log_info = {
            "step": "Ti·ªÅn x·ª≠ l√Ω ·∫£nh",
            "input_shape": image.shape,
            "enhanced_shape": enhanced.shape,
            "processing_time": f"{processing_time:.3f}s",
            "contrast_enhancement": "CLAHE applied",
            "conversion": "BGR ‚Üí LAB ‚Üí Enhanced ‚Üí Grayscale"
        }
        
        logger.info(f"‚úÖ {log_info['step']}: {log_info['processing_time']}")
        return gray, log_info
    
    def detect_edges(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """Ph√°t hi·ªán bi√™n v·ªõi backend linh ho·∫°t (Canny/DexiNed)"""
        start_time = time.time()
        
        if self.edge_backend == "canny":
            edges = cv2.Canny(gray, self.canny_low, self.canny_high)
            backend_info = f"Canny (low={self.canny_low}, high={self.canny_high})"
        else:
            # DexiNed fallback (simplified)
            edges = cv2.Canny(gray, 50, 150)
            backend_info = "DexiNed (fallback to Canny)"
        
        processing_time = time.time() - start_time
        edge_pixels = np.count_nonzero(edges)
        
        log_info = {
            "step": "Ph√°t hi·ªán bi√™n",
            "backend": self.edge_backend,
            "backend_info": backend_info,
            "edge_pixels": edge_pixels,
            "edge_density": f"{edge_pixels / (edges.shape[0] * edges.shape[1]) * 100:.2f}%",
            "processing_time": f"{processing_time:.3f}s",
            "edge_shape": edges.shape
        }
        
        logger.info(f"‚úÖ {log_info['step']}: {edge_pixels} pixels, {log_info['edge_density']}")
        return edges, log_info
    
    def filter_paired_edges(self, edges: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """L·ªçc c·∫∑p bi√™n v√† d·ª±ng m·∫∑t n·∫° v√≤ng"""
        start_time = time.time()
        
        # Dilation ƒë·ªÉ n·ªëi c√°c c·∫°nh g·∫ßn nhau
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        dilated = cv2.dilate(edges, kernel, iterations=1)
        
        # Morphological operations ƒë·ªÉ l√†m m·ªãn
        closed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel)
        
        # T√¨m contours
        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # L·ªçc contours theo di·ªán t√≠ch
        image_area = edges.shape[0] * edges.shape[1]
        min_area = image_area * self.min_area_ratio
        
        filtered_contours = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > min_area:
                # Ki·ªÉm tra aspect ratio
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0
                
                if self.aspect_ratio_min <= aspect_ratio <= self.aspect_ratio_max:
                    # T√≠nh rect score
                    rect_area = w * h
                    rect_score = area / rect_area if rect_area > 0 else 0
                    
                    if rect_score >= self.rect_score_min:
                        filtered_contours.append(contour)
        
        processing_time = time.time() - start_time
        
        log_info = {
            "step": "L·ªçc c·∫∑p bi√™n",
            "total_contours": len(contours),
            "filtered_contours": len(filtered_contours),
            "min_area_ratio": self.min_area_ratio,
            "min_area_pixels": int(min_area),
            "aspect_ratio_range": f"{self.aspect_ratio_min}-{self.aspect_ratio_max}",
            "rect_score_min": self.rect_score_min,
            "processing_time": f"{processing_time:.3f}s"
        }
        
        logger.info(f"‚úÖ {log_info['step']}: {len(filtered_contours)}/{len(contours)} contours passed")
        return filtered_contours, log_info
    
    def create_mask(self, contours: list, image_shape: Tuple[int, int]) -> Tuple[np.ndarray, Dict[str, Any]]:
        """T·∫°o m·∫∑t n·∫° t·ª´ contours v√† gi·ªØ th√†nh ph·∫ßn l·ªõn nh·∫•t"""
        start_time = time.time()
        
        if not contours:
            mask = np.zeros(image_shape, dtype=np.uint8)
            log_info = {
                "step": "T·∫°o m·∫∑t n·∫°",
                "mask_created": False,
                "reason": "No valid contours",
                "processing_time": f"{time.time() - start_time:.3f}s"
            }
            logger.warning(f"‚ö†Ô∏è {log_info['step']}: {log_info['reason']}")
            return mask, log_info
        
        # T√¨m contour l·ªõn nh·∫•t
        largest_contour = max(contours, key=cv2.contourArea)
        largest_area = cv2.contourArea(largest_contour)
        
        # T·∫°o mask
        mask = np.zeros(image_shape, dtype=np.uint8)
        cv2.fillPoly(mask, [largest_contour], 255)
        
        # Erode inner n·∫øu c·∫ßn
        if self.erode_inner > 0:
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (self.erode_inner, self.erode_inner))
            mask = cv2.erode(mask, kernel, iterations=1)
        
        # Convex hull n·∫øu c·∫ßn
        if self.convex_hull:
            hull = cv2.convexHull(largest_contour)
            mask = np.zeros(image_shape, dtype=np.uint8)
            cv2.fillPoly(mask, [hull], 255)
        
        # Ki·ªÉm tra mask size
        mask_area = np.count_nonzero(mask)
        image_area = image_shape[0] * image_shape[1]
        mask_ratio = mask_area / image_area
        
        processing_time = time.time() - start_time
        
        log_info = {
            "step": "T·∫°o m·∫∑t n·∫°",
            "largest_contour_area": int(largest_area),
            "mask_area": mask_area,
            "mask_ratio": f"{mask_ratio:.2%}",
            "erode_inner": self.erode_inner,
            "convex_hull": self.convex_hull,
            "mask_valid": mask_ratio < 0.8,  # Tr√°nh mask qu√° l·ªõn
            "processing_time": f"{processing_time:.3f}s"
        }
        
        logger.info(f"‚úÖ {log_info['step']}: {mask_area} pixels, {log_info['mask_ratio']}")
        return mask, log_info
    
    def rectify_mask(self, mask: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """√âp h√¨nh ch·ªØ nh·∫≠t v√† ki·ªÉm so√°t sai l·ªách"""
        start_time = time.time()
        
        # T√¨m contours trong mask
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            log_info = {
                "step": "√âp h√¨nh ch·ªØ nh·∫≠t",
                "rectify_mode": self.rectify_mode,
                "rectified": False,
                "reason": "No contours in mask",
                "processing_time": f"{time.time() - start_time:.3f}s"
            }
            logger.warning(f"‚ö†Ô∏è {log_info['step']}: {log_info['reason']}")
            return mask, log_info
        
        # L·∫•y contour l·ªõn nh·∫•t
        largest_contour = max(contours, key=cv2.contourArea)
        
        if self.rectify_mode == "robust":
            # Robust mode: erode-fit-pad
            # Erode ƒë·ªÉ gi·∫£m ·∫£nh h∆∞·ªüng ngo·∫°i lai
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            eroded = cv2.erode(mask, kernel, iterations=1)
            
            # T√¨m minAreaRect
            rect = cv2.minAreaRect(largest_contour)
            box = cv2.boxPoints(rect)
            box = np.intp(box)
            
            # T·∫°o mask t·ª´ rectangle
            rect_mask = np.zeros(mask.shape, dtype=np.uint8)
            cv2.fillPoly(rect_mask, [box], 255)
            
            # Th√™m padding
            if self.rect_pad > 0:
                kernel_pad = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, 
                                                      (self.rect_pad*2+1, self.rect_pad*2+1))
                rect_mask = cv2.dilate(rect_mask, kernel_pad, iterations=1)
            
            final_mask = rect_mask
            
        elif self.rectify_mode == "square":
            # Square mode
            x, y, w, h = cv2.boundingRect(largest_contour)
            size = max(w, h)
            center_x, center_y = x + w//2, y + h//2
            x1 = max(0, center_x - size//2)
            y1 = max(0, center_y - size//2)
            x2 = min(mask.shape[1], x1 + size)
            y2 = min(mask.shape[0], y1 + size)
            
            final_mask = np.zeros(mask.shape, dtype=np.uint8)
            final_mask[y1:y2, x1:x2] = 255
            
        else:  # rectangle
            x, y, w, h = cv2.boundingRect(largest_contour)
            final_mask = np.zeros(mask.shape, dtype=np.uint8)
            final_mask[y:y+h, x:x+w] = 255
        
        processing_time = time.time() - start_time
        
        log_info = {
            "step": "√âp h√¨nh ch·ªØ nh·∫≠t",
            "rectify_mode": self.rectify_mode,
            "rect_pad": self.rect_pad,
            "original_area": np.count_nonzero(mask),
            "rectified_area": np.count_nonzero(final_mask),
            "area_change": f"{np.count_nonzero(final_mask) / np.count_nonzero(mask) * 100:.1f}%" if np.count_nonzero(mask) > 0 else "0%",
            "processing_time": f"{processing_time:.3f}s"
        }
        
        logger.info(f"‚úÖ {log_info['step']}: {log_info['rectify_mode']} mode, {log_info['area_change']}")
        return final_mask, log_info
    
    def process_image(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, str]:
        """Pipeline ch√≠nh: x·ª≠ l√Ω ·∫£nh v√† t·∫°o mask"""
        total_start = time.time()
        
        # Step 1: Ti·ªÅn x·ª≠ l√Ω
        gray, preprocess_log = self.preprocess_image(image)
        
        # Step 2: Ph√°t hi·ªán bi√™n
        edges, edge_log = self.detect_edges(gray)
        
        # Step 3: L·ªçc c·∫∑p bi√™n
        contours, filter_log = self.filter_paired_edges(edges)
        
        # Step 4: T·∫°o mask
        mask, mask_log = self.create_mask(contours, gray.shape)
        
        # Step 5: Rectify mask
        final_mask, rectify_log = self.rectify_mask(mask)
        
        total_time = time.time() - total_start
        
        # T·∫°o log chi ti·∫øt v·ªõi ghi ch√∫ t·ª´ng ·∫£nh
        detailed_log = f"""
üîç WHITE RING SEGMENTATION PIPELINE - B√ÅO C√ÅO CHI TI·∫æT
{'='*80}

üìä T·ªîNG QUAN H·ªÜ TH·ªêNG:
‚Ä¢ Th·ªùi gian x·ª≠ l√Ω t·ªïng: {total_time:.3f}s
‚Ä¢ K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o: {image.shape[1]}x{image.shape[0]} pixels
‚Ä¢ Backend ph√°t hi·ªán bi√™n: {self.edge_backend.upper()}
‚Ä¢ Ch·∫ø ƒë·ªô √©p h√¨nh: {self.rectify_mode.upper()}

üîÑ PIPELINE X·ª¨ L√ù - ·∫¢NH ƒê·∫¶U V√ÄO ‚Üí BI√äN ‚Üí L·ªåC C·∫∂P BI√äN ‚Üí MASK L·ªöN NH·∫§T ‚Üí √âP H√åNH

1Ô∏è‚É£ ·∫¢NH ƒê·∫¶U V√ÄO (INPUT IMAGE):
   üì∏ Th√¥ng tin ·∫£nh g·ªëc:
   ‚Ä¢ ƒê·ªãnh d·∫°ng: BGR Color Image
   ‚Ä¢ K√≠ch th∆∞·ªõc: {image.shape[1]}x{image.shape[0]} pixels
   ‚Ä¢ S·ªë k√™nh m√†u: {image.shape[2]}
   ‚Ä¢ Ki·ªÉu d·ªØ li·ªáu: {image.dtype}
   ‚Ä¢ Gi√° tr·ªã min-max: {image.min()}-{image.max()}

2Ô∏è‚É£ TI·ªÄN X·ª¨ L√ù ·∫¢NH (PREPROCESSING):
   üé® Chu·∫©n ho√° ƒë·ªô t∆∞∆°ng ph·∫£n-chi ti·∫øt:
   ‚Ä¢ Ph∆∞∆°ng ph√°p: CLAHE (Contrast Limited Adaptive Histogram Equalization)
   ‚Ä¢ Chuy·ªÉn ƒë·ªïi kh√¥ng gian m√†u: BGR ‚Üí LAB ‚Üí Enhanced ‚Üí Grayscale
   ‚Ä¢ K√≠ch th∆∞·ªõc tile grid: 8x8 pixels
   ‚Ä¢ Clip limit: 2.0
   ‚Ä¢ Th·ªùi gian x·ª≠ l√Ω: {preprocess_log['processing_time']}
   ‚Ä¢ K√≠ch th∆∞·ªõc ·∫£nh sau x·ª≠ l√Ω: {preprocess_log['enhanced_shape'][1]}x{preprocess_log['enhanced_shape'][0]}

3Ô∏è‚É£ PH√ÅT HI·ªÜN BI√äN (EDGE DETECTION):
   üîç Backend: {edge_log['backend_info']}
   ‚Ä¢ S·ªë pixel bi√™n ƒë∆∞·ª£c ph√°t hi·ªán: {edge_log['edge_pixels']:,} pixels
   ‚Ä¢ M·∫≠t ƒë·ªô bi√™n trong ·∫£nh: {edge_log['edge_density']}
   ‚Ä¢ T·ª∑ l·ªá bi√™n/·∫£nh: {edge_log['edge_pixels']/(edge_log['edge_shape'][0]*edge_log['edge_shape'][1])*100:.2f}%
   ‚Ä¢ K√≠ch th∆∞·ªõc ·∫£nh bi√™n: {edge_log['edge_shape'][1]}x{edge_log['edge_shape'][0]}
   ‚Ä¢ Th·ªùi gian x·ª≠ l√Ω: {edge_log['processing_time']}

4Ô∏è‚É£ L·ªåC C·∫∂P BI√äN (PAIRED EDGES FILTERING):
   üîó Morphological operations + Contour filtering:
   ‚Ä¢ T·ªïng s·ªë contours ph√°t hi·ªán: {filter_log['total_contours']}
   ‚Ä¢ Contours v∆∞·ª£t qua b·ªô l·ªçc: {filter_log['filtered_contours']}
   ‚Ä¢ T·ª∑ l·ªá l·ªçc th√†nh c√¥ng: {filter_log['filtered_contours']/filter_log['total_contours']*100:.1f}%
   ‚Ä¢ Di·ªán t√≠ch t·ªëi thi·ªÉu y√™u c·∫ßu: {filter_log['min_area_ratio']:.1%} c·ªßa ·∫£nh
   ‚Ä¢ S·ªë pixel di·ªán t√≠ch t·ªëi thi·ªÉu: {filter_log['min_area_pixels']:,} pixels
   ‚Ä¢ Kho·∫£ng t·ª∑ l·ªá khung h√¨nh cho ph√©p: {filter_log['aspect_ratio_range']}
   ‚Ä¢ ƒêi·ªÉm s·ªë h√¨nh ch·ªØ nh·∫≠t t·ªëi thi·ªÉu: {filter_log['rect_score_min']:.1f}
   ‚Ä¢ Th·ªùi gian x·ª≠ l√Ω: {filter_log['processing_time']}

5Ô∏è‚É£ T·∫†O M·∫∂T NƒÇNG (MASK CREATION):
   üé≠ Gi·ªØ contour l·ªõn nh·∫•t v√† t·∫°o mask:
   ‚Ä¢ Di·ªán t√≠ch contour l·ªõn nh·∫•t: {mask_log['largest_contour_area']:,} pixels
   ‚Ä¢ Di·ªán t√≠ch mask cu·ªëi c√πng: {mask_log['mask_area']:,} pixels
   ‚Ä¢ T·ª∑ l·ªá mask so v·ªõi ·∫£nh: {mask_log['mask_ratio']}
   ‚Ä¢ S·ªë pixel mask: {mask_log['mask_area']:,} / {image.shape[0]*image.shape[1]:,} pixels
   ‚Ä¢ ƒÇn m√≤n ph√≠a trong: {mask_log['erode_inner']} pixels
   ‚Ä¢ S·ª≠ d·ª•ng Convex Hull: {'C√≥' if mask_log['convex_hull'] else 'Kh√¥ng'}
   ‚Ä¢ Mask h·ª£p l·ªá: {'‚úÖ C√≥' if mask_log['mask_valid'] else '‚ùå Kh√¥ng (qu√° l·ªõn)'}
   ‚Ä¢ Th·ªùi gian x·ª≠ l√Ω: {mask_log['processing_time']}

6Ô∏è‚É£ √âP H√åNH CH·ªÆ NH·∫¨T (RECTIFICATION):
   üìê Ch·∫ø ƒë·ªô {rectify_log['rectify_mode'].upper()}:
   ‚Ä¢ Padding th√™m: {rectify_log['rect_pad']} pixels
   ‚Ä¢ Di·ªán t√≠ch mask g·ªëc: {rectify_log['original_area']:,} pixels
   ‚Ä¢ Di·ªán t√≠ch mask sau √©p: {rectify_log['rectified_area']:,} pixels
   ‚Ä¢ Thay ƒë·ªïi di·ªán t√≠ch: {rectify_log['area_change']}
   ‚Ä¢ S·ªë pixel thay ƒë·ªïi: {rectify_log['rectified_area'] - rectify_log['original_area']:,} pixels
   ‚Ä¢ Th·ªùi gian x·ª≠ l√Ω: {rectify_log['processing_time']}

üìà K·∫æT QU·∫¢ CU·ªêI C√ôNG:
‚Ä¢ ‚úÖ Pipeline ho√†n th√†nh th√†nh c√¥ng
‚Ä¢ üéØ T·ª∑ l·ªá contours h·ª£p l·ªá: {filter_log['filtered_contours']}/{filter_log['total_contours']} ({filter_log['filtered_contours']/filter_log['total_contours']*100:.1f}%)
‚Ä¢ ‚ö° Hi·ªáu su·∫•t x·ª≠ l√Ω: {total_time:.3f}s cho ·∫£nh {image.shape[1]}x{image.shape[0]}
‚Ä¢ üîÑ T·ªëc ƒë·ªô x·ª≠ l√Ω: {image.shape[0]*image.shape[1]/total_time/1000:.1f} MPix/s
‚Ä¢ üìä T·ª∑ l·ªá mask cu·ªëi c√πng: {np.count_nonzero(final_mask)/(image.shape[0]*image.shape[1])*100:.2f}% c·ªßa ·∫£nh

üé® GHI CH√ö ·∫¢NH TRONG PIPELINE:
‚Ä¢ ·∫¢nh 1: INPUT - ·∫¢nh BGR g·ªëc t·ª´ camera/upload
‚Ä¢ ·∫¢nh 2: PREPROCESSED - ·∫¢nh grayscale sau CLAHE enhancement  
‚Ä¢ ·∫¢nh 3: EDGES - ·∫¢nh bi√™n tr·∫Øng-ƒëen t·ª´ Canny/DexiNed
‚Ä¢ ·∫¢nh 4: FILTERED - Contours sau morphological operations
‚Ä¢ ·∫¢nh 5: MASK - V√πng tr·∫Øng l√† h·ªôp ch·ª©a ƒë∆∞·ª£c segment
‚Ä¢ ·∫¢nh 6: RECTIFIED - Mask ƒë√£ √©p th√†nh h√¨nh ch·ªØ nh·∫≠t chu·∫©n
        """
        
        return final_mask, edges, gray, mask, final_mask, detailed_log

def create_gradio_interface():
    """T·∫°o giao di·ªán Gradio"""
    
    segmenter = WhiteRingSegmenter()
    
    def process_uploaded_image(image):
        """X·ª≠ l√Ω ·∫£nh ƒë∆∞·ª£c upload"""
        if image is None:
            return None, None, None, None, None, "‚ùå Vui l√≤ng upload ·∫£nh!"
        
        try:
            # X·ª≠ l√Ω ·∫£nh
            final_mask, edges, gray, mask, rectified_mask, log = segmenter.process_image(image)
            
            # T·∫°o ·∫£nh k·∫øt qu·∫£ v·ªõi overlay
            result_image = image.copy()
            result_image[final_mask > 0] = [0, 255, 0]  # M√†u xanh cho v√πng ƒë∆∞·ª£c segment
            
            # Overlay mask
            overlay = cv2.addWeighted(image, 0.7, cv2.cvtColor(final_mask, cv2.COLOR_GRAY2BGR), 0.3, 0)
            
            return overlay, edges, gray, mask, rectified_mask, log
            
        except Exception as e:
            error_msg = f"‚ùå L·ªói x·ª≠ l√Ω: {str(e)}"
            logger.error(error_msg)
            return None, None, None, None, None, error_msg
    
    # T·∫°o giao di·ªán
    with gr.Blocks(title="White Ring Segmentation Demo", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # üîç White Ring Segmentation Demo
        
        **M·ª•c ti√™u**: T√°ch ch√≠nh x√°c v√πng "h·ªôp ch·ª©a" b·∫±ng pipeline d·ª±a v√†o bi√™n tr·∫Øng quanh th√†nh h·ªôp.
        
        **Pipeline**: Ti·ªÅn x·ª≠ l√Ω ‚Üí Ph√°t hi·ªán bi√™n ‚Üí L·ªçc c·∫∑p bi√™n ‚Üí T·∫°o mask ‚Üí √âp h√¨nh ch·ªØ nh·∫≠t
        """)
        
        with gr.Row():
            with gr.Column():
                input_image = gr.Image(label="üì∏ Upload ·∫£nh", type="numpy")
                process_btn = gr.Button("üöÄ X·ª≠ l√Ω ·∫£nh", variant="primary")
                
                # Tham s·ªë ƒëi·ªÅu ch·ªânh
                gr.Markdown("### ‚öôÔ∏è Tham s·ªë ƒëi·ªÅu ch·ªânh")
                with gr.Row():
                    canny_low = gr.Slider(10, 100, 50, step=5, label="Canny Low")
                    canny_high = gr.Slider(100, 300, 150, step=10, label="Canny High")
                
                with gr.Row():
                    min_area_ratio = gr.Slider(0.01, 0.5, 0.1, step=0.01, label="Min Area Ratio")
                    rect_score_min = gr.Slider(0.1, 1.0, 0.7, step=0.1, label="Rect Score Min")
                
                with gr.Row():
                    rectify_mode = gr.Dropdown(["robust", "square", "rectangle"], value="robust", label="Rectify Mode")
                    rect_pad = gr.Slider(0, 20, 8, step=1, label="Rect Padding")
            
            with gr.Column():
                gr.Markdown("### üîÑ Pipeline Images")
                with gr.Row():
                    output_image = gr.Image(label="üéØ K·∫øt qu·∫£ cu·ªëi", type="numpy")
                    edges_image = gr.Image(label="üîç ·∫¢nh bi√™n", type="numpy")
                
                with gr.Row():
                    gray_image = gr.Image(label="üé® ·∫¢nh grayscale", type="numpy")
                    mask_image = gr.Image(label="üé≠ Mask g·ªëc", type="numpy")
                
                rectified_image = gr.Image(label="üìê Mask ƒë√£ √©p", type="numpy")
                detailed_log = gr.Textbox(label="üìã Log chi ti·∫øt", lines=15, max_lines=20)
        
        # Event handlers
        def update_params(low, high, area_ratio, rect_score, mode, pad):
            segmenter.canny_low = int(low)
            segmenter.canny_high = int(high)
            segmenter.min_area_ratio = area_ratio
            segmenter.rect_score_min = rect_score
            segmenter.rectify_mode = mode
            segmenter.rect_pad = int(pad)
        
        def process_with_params(image, low, high, area_ratio, rect_score, mode, pad):
            if image is None:
                return None, None, None, None, None, "‚ùå Vui l√≤ng upload ·∫£nh!"
            
            # C·∫≠p nh·∫≠t tham s·ªë
            update_params(low, high, area_ratio, rect_score, mode, pad)
            
            try:
                final_mask, edges, gray, mask, rectified_mask, log = segmenter.process_image(image)
                
                # T·∫°o ·∫£nh k·∫øt qu·∫£ v·ªõi overlay
                result_image = image.copy()
                result_image[final_mask > 0] = [0, 255, 0]
                overlay = cv2.addWeighted(image, 0.7, cv2.cvtColor(final_mask, cv2.COLOR_GRAY2BGR), 0.3, 0)
                
                return overlay, edges, gray, mask, rectified_mask, log
                
            except Exception as e:
                error_msg = f"‚ùå L·ªói x·ª≠ l√Ω: {str(e)}"
                return None, None, None, None, None, error_msg
        
        # Bind events
        process_btn.click(
            fn=process_with_params,
            inputs=[input_image, canny_low, canny_high, min_area_ratio, rect_score_min, rectify_mode, rect_pad],
            outputs=[output_image, edges_image, gray_image, mask_image, rectified_image, detailed_log]
        )
        
        # Auto process when image changes
        input_image.change(
            fn=process_with_params,
            inputs=[input_image, canny_low, canny_high, min_area_ratio, rect_score_min, rectify_mode, rect_pad],
            outputs=[output_image, edges_image, gray_image, mask_image, rectified_image, detailed_log]
        )
    
    return demo

if __name__ == "__main__":
    # T·∫°o v√† ch·∫°y demo
    demo = create_gradio_interface()
    demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,
        debug=True
    )
